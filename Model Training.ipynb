{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cl_N7t3odrBn",
        "outputId": "b5d09367-3d61-4010-d8a4-e358f4b6d3c6"
      },
      "outputs": [],
      "source": [
        "#IMPORTS\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Pre-process the documents\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('omw-1.4')\n",
        "    #Lowercase Converter\n",
        "i=0\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "for row in df.itertuples():\n",
        "    Document1 = row.Text\n",
        "    Document1 = Document1.lower()\n",
        "        #Sentence Splitter\n",
        "    arr1 = Document1.split()\n",
        "        #Spelling Corrector - not needed\n",
        "        #Contraction Expander - not needed\n",
        "        #Punctuation Remover\n",
        "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    for i in range(len(arr1)):\n",
        "        arr1[i] = arr1[i].translate(str.maketrans('', '', punc))\n",
        "        #Non-alphanumeric Remover - not needed\n",
        "        #Stopword Remover\n",
        "    arr1 = [s for s in arr1 if s not in stopwords.words('english')]\n",
        "        #Emoji Remover - not needed\n",
        "        #Hashtag Remover - not needed\n",
        "        #Word Lemmatizer from https://stackoverflow.com/questions/52393591/nltk-lemmatizer-extract-meaningful-words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    for i in range(len(arr1)):\n",
        "        arr1[i] = lemmatizer.lemmatize(arr1[i])\n",
        "        #Rejoin\n",
        "    arr1 = ' '.join(arr1)\n",
        "    df.at[i, 'Text'] = arr1\n",
        "    i = i + 1\n",
        "    #print(arr1)\n",
        "df.to_csv('Processed.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TOKINER AN DATA SET-UP\n",
        "pdf = pd.read_csv('Processed.csv')\n",
        "pdf['Sentiments'] = pdf.Score.apply(lambda x: 0 if x in [1, 2] else 1)\n",
        "\n",
        "train=pdf.sample(frac=0.8,random_state=200) #random state is a seed value\n",
        "test=pdf.drop(train.index)\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train.Text)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(train.Text)\n",
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=120)\n",
        "testing_sentences = tokenizer.texts_to_sequences(test.Text)\n",
        "testing_padded = tf.keras.preprocessing.sequence.pad_sequences(testing_sentences, maxlen=120)\n",
        "\n",
        "training_labels_final = np.array(train.Sentiments)\n",
        "testing_labels_final = np.array(test.Sentiments)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 120, 16)           7276208   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 102       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,276,317\n",
            "Trainable params: 7,276,317\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 77s 77ms/step - loss: 0.4192 - accuracy: 0.8550 - val_loss: 0.3556 - val_accuracy: 0.8551\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 78s 78ms/step - loss: 0.2794 - accuracy: 0.8819 - val_loss: 0.2411 - val_accuracy: 0.9021\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 78s 78ms/step - loss: 0.2286 - accuracy: 0.9066 - val_loss: 0.2203 - val_accuracy: 0.9105\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 78s 78ms/step - loss: 0.2150 - accuracy: 0.9123 - val_loss: 0.2118 - val_accuracy: 0.9152\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 77s 77ms/step - loss: 0.2092 - accuracy: 0.9162 - val_loss: 0.2068 - val_accuracy: 0.9180\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 77s 77ms/step - loss: 0.2028 - accuracy: 0.9200 - val_loss: 0.2026 - val_accuracy: 0.9196\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 78s 78ms/step - loss: 0.1987 - accuracy: 0.9208 - val_loss: 0.1993 - val_accuracy: 0.9207\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1903 - accuracy: 0.9255 - val_loss: 0.1973 - val_accuracy: 0.9211\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1836 - accuracy: 0.9270 - val_loss: 0.1967 - val_accuracy: 0.9203\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 81s 81ms/step - loss: 0.1844 - accuracy: 0.9270 - val_loss: 0.1929 - val_accuracy: 0.9231\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f64d992e80>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#RNN\n",
        "model1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(training_labels_final), 16, input_length=120),\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model1.summary())\n",
        "\n",
        "history1 = model1.fit(padded, training_labels_final, epochs=10, steps_per_epoch=1000, batch_size=64, validation_data=(testing_padded, testing_labels_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.62      0.70     16493\n",
            "           1       0.94      0.97      0.96     97198\n",
            "\n",
            "    accuracy                           0.92    113691\n",
            "   macro avg       0.87      0.80      0.83    113691\n",
            "weighted avg       0.92      0.92      0.92    113691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#RNN RESULTS\n",
        "print(\"RNN:\")\n",
        "pred = model1.predict(testing_padded)\n",
        "pred[pred>=0.5]=1\n",
        "pred[pred<0.5]=0\n",
        "pred.astype(int)\n",
        "print(sklearn.metrics.classification_report(y_true=testing_labels_final, y_pred=pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 120, 16)           7276208   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               46800     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 6)                 606       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,323,621\n",
            "Trainable params: 7,323,621\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 193s 191ms/step - loss: 0.2756 - accuracy: 0.8910 - val_loss: 0.2227 - val_accuracy: 0.9089\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 189s 189ms/step - loss: 0.2143 - accuracy: 0.9137 - val_loss: 0.2090 - val_accuracy: 0.9147\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 185s 185ms/step - loss: 0.2061 - accuracy: 0.9178 - val_loss: 0.2001 - val_accuracy: 0.9177\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 189s 189ms/step - loss: 0.1963 - accuracy: 0.9202 - val_loss: 0.1990 - val_accuracy: 0.9177\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 190s 190ms/step - loss: 0.1870 - accuracy: 0.9252 - val_loss: 0.1797 - val_accuracy: 0.9286\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 187s 187ms/step - loss: 0.1805 - accuracy: 0.9284 - val_loss: 0.1709 - val_accuracy: 0.9325\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 189s 189ms/step - loss: 0.1709 - accuracy: 0.9322 - val_loss: 0.1672 - val_accuracy: 0.9341\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 189s 189ms/step - loss: 0.1459 - accuracy: 0.9431 - val_loss: 0.1684 - val_accuracy: 0.9351\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 193s 193ms/step - loss: 0.1420 - accuracy: 0.9446 - val_loss: 0.1607 - val_accuracy: 0.9356\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 197s 197ms/step - loss: 0.1428 - accuracy: 0.9437 - val_loss: 0.1554 - val_accuracy: 0.9391\n"
          ]
        }
      ],
      "source": [
        "#LSTM\n",
        "model2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(len(training_labels_final), 16, input_length=120),\n",
        "    tf.keras.layers.LSTM(100),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model2.summary())\n",
        "\n",
        "history2 = model2.fit(padded, training_labels_final, epochs=10, steps_per_epoch=1000, batch_size=64, validation_data=(testing_padded, testing_labels_final))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.77      0.78     16493\n",
            "           1       0.96      0.97      0.96     97198\n",
            "\n",
            "    accuracy                           0.94    113691\n",
            "   macro avg       0.88      0.87      0.87    113691\n",
            "weighted avg       0.94      0.94      0.94    113691\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#LSTM RESULTS\n",
        "print(\"LSTM:\")\n",
        "pred = model2.predict(testing_padded)\n",
        "pred[pred>=0.5]=1\n",
        "pred[pred<0.5]=0\n",
        "pred.astype(int)\n",
        "print(sklearn.metrics.classification_report(y_true=testing_labels_final, y_pred=pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hw6Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
