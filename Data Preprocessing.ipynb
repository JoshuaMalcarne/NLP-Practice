{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "cl_N7t3odrBn",
        "outputId": "b5d09367-3d61-4010-d8a4-e358f4b6d3c6"
      },
      "outputs": [],
      "source": [
        "#IMPORTS\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DOCUMENTS\n",
        "#a\n",
        "Doc1 = \"The cat chased a rat.\"\n",
        "Doc2 = \"A big rat chased the big dog.\"\n",
        "#b\n",
        "Document1 = \"Mr Jeremy put on a macintosh, and a pair of shiny shoes; he took his fishing rod and basket, and set off  with enormous hops to the place where he kept his boat. The boat was round and green, and very like the other lily leaves. It was tied to a water-plant in the middle of the pond.\"\n",
        "Document2 = \"Peter never stopped running or looked behind him till he got home to the big fir-tree. He was so tired that  he flopped down upon the nice soft sand on the floor of the rabbit-hole and shut his eyes. His mother was busy  cooking; she wondered what he had done with his clothes. It was the second little jacket and pair of shoes that Peter  had lost in a week!\" \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   big  cat  chased  dog  rat  the\n",
            "0    0    1       1    0    1    1\n",
            "1    2    0       1    1    1    1\n",
            "[[0.53033009]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joshua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#BAG OF WORDS\n",
        "bow = CountVectorizer()\n",
        "bowvectors = bow.fit_transform([Doc1, Doc2])\n",
        "bowfeature_names = bow.get_feature_names()\n",
        "bowdense = bowvectors.todense()\n",
        "bowdenselist = bowdense.tolist()\n",
        "bowdf = pd.DataFrame(bowdenselist, columns=bowfeature_names)\n",
        "print(bowdf)\n",
        "print(cosine_similarity(bowvectors[0], bowvectors[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   big rat chased  cat chased rat  chased the big  rat chased the  \\\n",
            "0               0               1               0               0   \n",
            "1               1               0               1               1   \n",
            "\n",
            "   the big dog  the cat chased  \n",
            "0            0               1  \n",
            "1            1               0  \n",
            "[[0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joshua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#BAG OF 3-GRAMS\n",
        "bong = CountVectorizer(ngram_range=(3,3))\n",
        "bongvectors = bong.fit_transform([Doc1, Doc2])\n",
        "bongfeature_names = bong.get_feature_names()\n",
        "bongdense = bongvectors.todense()\n",
        "bongdenselist = bongdense.tolist()\n",
        "bongdf = pd.DataFrame(bongdenselist, columns=bongfeature_names)\n",
        "print(bongdf)\n",
        "print(cosine_similarity(bongvectors[0], bongvectors[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        big       cat    chased       dog       rat       the\n",
            "0  0.000000  0.630099  0.448321  0.000000  0.448321  0.448321\n",
            "1  0.783337  0.000000  0.278675  0.391668  0.278675  0.278675\n",
            "[[0.37480777]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joshua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidfvectors = tfidf.fit_transform([Doc1, Doc2])\n",
        "tfidffeature_names = tfidf.get_feature_names()\n",
        "tfidfdense = tfidfvectors.todense()\n",
        "tfidfdenselist = tfidfdense.tolist()\n",
        "tfidfdf = pd.DataFrame(tfidfdenselist, columns=tfidffeature_names)\n",
        "print(tfidfdf)\n",
        "print(cosine_similarity(tfidfvectors[0], tfidfvectors[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mr jeremy put macintosh pair shiny shoe took fishing rod basket set enormous hop place kept boat boat round green like lily leaf tied waterplant middle pond\n",
            "peter never stopped running looked behind till got home big firtree tired flopped upon nice soft sand floor rabbithole shut eye mother busy cooking wondered done clothes second little jacket pair shoe peter lost week\n",
            "    basket    behind       big     boat      busy   clothes   cooking  \\\n",
            "0  0.18894  0.000000  0.000000  0.37788  0.000000  0.000000  0.000000   \n",
            "1  0.00000  0.166638  0.166638  0.00000  0.166638  0.166638  0.166638   \n",
            "\n",
            "       done  enormous       eye  ...      soft   stopped     tied      till  \\\n",
            "0  0.000000   0.18894  0.000000  ...  0.000000  0.000000  0.18894  0.000000   \n",
            "1  0.166638   0.00000  0.166638  ...  0.166638  0.166638  0.00000  0.166638   \n",
            "\n",
            "      tired     took      upon  waterplant      week  wondered  \n",
            "0  0.000000  0.18894  0.000000     0.18894  0.000000  0.000000  \n",
            "1  0.166638  0.00000  0.166638     0.00000  0.166638  0.166638  \n",
            "\n",
            "[2 rows x 58 columns]\n",
            "[[0.03187773]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Joshua\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#PART B\n",
        "#Pre-process the documents\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "#nltk.download('omw-1.4')\n",
        "    #Lowercase Converter\n",
        "Document1 = Document1.lower()\n",
        "Document2 = Document2.lower()\n",
        "    #Sentence Splitter\n",
        "arr1 = Document1.split()\n",
        "arr2 = Document2.split()\n",
        "    #Spelling Corrector - not needed\n",
        "    #Contraction Expander - not needed\n",
        "    #Punctuation Remover\n",
        "punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "for i in range(len(arr1)):\n",
        "    arr1[i] = arr1[i].translate(str.maketrans('', '', punc))\n",
        "for i in range(len(arr2)):\n",
        "    arr2[i] = arr2[i].translate(str.maketrans('', '', punc))\n",
        "    #Non-alphanumeric Remover - not needed\n",
        "    #Stopword Remover\n",
        "arr1 = [s for s in arr1 if s not in stopwords.words('english')]\n",
        "arr2 = [s for s in arr2 if s not in stopwords.words('english')]\n",
        "    #Emoji Remover - not needed\n",
        "    #Hashtag Remover - not needed\n",
        "    #Word Lemmatizer from https://stackoverflow.com/questions/52393591/nltk-lemmatizer-extract-meaningful-words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for i in range(len(arr1)):\n",
        "    arr1[i] = lemmatizer.lemmatize(arr1[i])\n",
        "for i in range(len(arr2)):\n",
        "    arr2[i] = lemmatizer.lemmatize(arr2[i])\n",
        "    #Rejoin\n",
        "arr1 = ' '.join(arr1)\n",
        "arr2 = ' '.join(arr2)\n",
        "print(arr1)\n",
        "print(arr2)\n",
        "\n",
        "#Generate the TF-IDF Vectors\n",
        "vectorizer1 = TfidfVectorizer()\n",
        "vector1 = vectorizer1.fit_transform([arr1, arr2])\n",
        "feature_names1 = vectorizer1.get_feature_names()\n",
        "dense1 = vector1.todense()\n",
        "denselist1 = dense1.tolist()\n",
        "df1 = pd.DataFrame(denselist1, columns=feature_names1)\n",
        "print(df1)\n",
        "\n",
        "#Compute Cosine Similarity\n",
        "print(cosine_similarity(vector1[0], vector1[1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Hw6Q3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
